{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"top\"></div> \n",
    "# Table of contents\n",
    "* <a href='#Submission-instructions'>Submission instructions</a>\n",
    "* <a href=\"#A-short-introduction-to-LaTeX\">A short introduction to LaTeX</a>\n",
    "* <a href=\"#Some-useful-numpy-functions\">Some useful numpy functions</a>\n",
    "* <a href=\"#The-start-of-this-homework\">The start of this homework</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission instructions\n",
    "See announcement on Sakai for instructions. Do NOT email the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short introduction to LaTeX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "$ \\LaTeX $ is a markup language to typeset documents. You can use it to express math compactly and make the layout of your documents beautiful. For the purpose of this class, we focus on the first piece, that is writing mathematical formulations. Jupyter implements a subset of $\\LaTeX$. Therefore, you can use $ \\LaTeX $ to answers the problems in the assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two modes in latex that can typeset the formulations\n",
    "1. Inline mode, start with an \\$, end with an \\$ (\\$...\\$). E.g. $a + b = \\frac{1}{3}$\n",
    "2. Display mode, start with two \\$\\$, end with two \\$\\$ (\\$\\$...\\$\\$). E.g. $$a+b=\\frac{1}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Maths\n",
    "1. It is straight-forward for basic arithmetic operations. E.g. $+, - * /, a^b, a_b$.\n",
    "2. $ \\LaTeX$ already defined many useful symbols, macros, (or functions) to typeset the formulations. They start with \\, such as \\LaTeX is for the latex symbol. In some typeset functions you can give them parameters. E.g. \\frac{1}{3} typesets one over three, where the thing within the first {} is nominator, and the thing within the second {} is denominator. {} also helps group thing within it together. Consider the difference between a\\_b+1 ($a_b+1$) and a\\_{b+1} ($a_{b+1}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful symbols and functions\n",
    "1. fraction, \\frac{1}{3}. ($\\frac{1}{3}$)\n",
    "2. partial derivative, \\partial. ($\\partial$), Combined with 1), we have \\frac{\\partial f}{\\partial x}. ($\\frac{\\partial f}{\\partial x}$)\n",
    "3. summation, \\sum\\_{i=1}^{N}. ($\\sum_{i=1}^{N}$)\n",
    "4. products, \\prod\\_{i=1}^{N}. ($\\prod_{i=1}^{N}$)\n",
    "5. indexing, w\\_{i, j}. ($w_{i, j}$)\n",
    "6. frequently used Greek letters \\alpha, \\beta, \\gamma. ($\\alpha, \\beta, \\gamma$)\n",
    "7. gradient notation \\nabla. ($\\nabla$)\n",
    "8. vector forms $\\text{\\\\begin{bmatrix} x_{i, 1} \\\\ \\vdots \\\\ x_{i, p+1}  \\\\end{bmatrix}}$. ($\\begin{bmatrix} x_{i, 1} \\\\ \\vdots \\\\ x_{i, p+1} \\end{bmatrix}$) <br \\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful numpy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People usualy import numpy as the follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce some useful numpy functions that you might use in this homework.\n",
    "* zeros <br \\>\n",
    "zeros generates a multi-dimensional array that contains all zeros. <br \\>\n",
    "    * Example: <br \\>\n",
    "    ** zeros( (3, 2) ) ** generates a 2d array of size 3\\*2 (three rows and 2 columns) that contains zeros in all entries. <br \\>\n",
    "    ** zeros( (3, 2, 4) )** generates a 3d array of size 3\\*2\\*4 that also contains zero in all entries.\n",
    "* ones <br \\>\n",
    "Similar to zeros, ones generates a multi-dimensional array that contains all ones. <br \\>\n",
    "* exp <br \\>\n",
    "exp takes exponential on each entry of the input. <br \\>\n",
    "    * Example: <br \\>\n",
    "    ** exp(3) ** computes $ e^3 $. <br \\>\n",
    "    ** exp( [1, 2, 3] ) ** computes $[ e^1, e^2, e^3]$.\n",
    "* log <br \\>\n",
    "Similar to exp, log takes log on each entry of the input. Since log function is not defined on the values $<= 0$, if the input of log is like that, it will output nan or inf defined in numpy. <br \\>\n",
    "* sum <br \\>\n",
    "sum takes sum over an axis of the input array. <br \\>\n",
    "    * Example: please see the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input array is a 3*3 matrix, values: \n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "result 1 is  [ 9 12 15]\n",
      "result 2 is  [ 3 12 21]\n"
     ]
    }
   ],
   "source": [
    "matrixA = np.arange(9).reshape(3, 3)\n",
    "print( 'input array is a 3*3 matrix, values: \\n', matrixA )\n",
    "result1 = np.sum(matrixA, axis = 0)\n",
    "result2 = np.sum(matrixA, axis = 1)\n",
    "print( 'result 1 is ', result1 )\n",
    "print( 'result 2 is ', result2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dot <br \\>\n",
    "do dot-product of the two inputs (if they are vectors), or do matrix multiplication of the two inputs (if they are 2d arrays). In numpy if A and B are both arrays, A\\*B computes the element-wise multiplication, not matrix multiplication. To use dot, the dimensions of the two inputs must be valid. <br \\>\n",
    "    * Example: please see the following code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dot product examples\n",
    "vector1 = np.array( [1, 2, 3] )\n",
    "vector2 = np.array( [1, 2, 1] )\n",
    "print( 'vecotr 1 is a length-3 vector, values: ', vector1 )\n",
    "print( 'vecotr 2 is a length-3 vector, values: ', vector2 )\n",
    "print( 'dot product of vecotr 1 and 2 is', np.dot(vector1, vector2) )\n",
    "vector3 = np.array( [1, 2, 1, 2])\n",
    "print( 'dot product of vecotr 1 and 3 generates error' )\n",
    "np.dot(vector1, vector3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix1 is a 2*3 matrix, values: \n",
      "  [[0 1 2]\n",
      " [3 4 5]]\n",
      "matrix2 is a 3*1 matrix, values: \n",
      "  [[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "matrix1 multiplies matrix2 is a 2*1 matrix: \n",
      "  [[  3.]\n",
      " [ 12.]]\n"
     ]
    }
   ],
   "source": [
    "#matrix multiplication examples\n",
    "matrix1 = np.arange(6).reshape(2, 3)\n",
    "matrix2 = np.ones(((3,1)))\n",
    "print( 'matrix1 is a 2*3 matrix, values: \\n ', matrix1 )\n",
    "print( 'matrix2 is a 3*1 matrix, values: \\n ', matrix2 )\n",
    "print( 'matrix1 multiplies matrix2 is a 2*1 matrix: \\n ', np.dot(matrix1, matrix2) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* T <br \\>\n",
    "[numpy matrix variable].T, takes transpose of the input matrix variable.\n",
    "    * Example: please see the following code cell <br \\>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix1 = np.ones( (4, 3) )\n",
    "print( 'matrix dimension is',  matrix1.shape )\n",
    "print( 'matrix dimension after transpose is', matrix1.T.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The start of this homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should take at most 30 seconds\n",
      "Time elapsed (seconds): 0.007996082305908203\n"
     ]
    }
   ],
   "source": [
    "#download data\n",
    "import time\n",
    "import urllib\n",
    "import os.path\n",
    "import sys\n",
    "versionName = sys.version_info\n",
    "if versionName[0] == 2:\n",
    "    import urllib as U\n",
    "elif versionName[0] == 3:\n",
    "    import urllib.request as U\n",
    "start = time.time()\n",
    "print(\"Should take at most 30 seconds\")\n",
    "if not os.path.isfile('train_data.pgz'):\n",
    "    U.urlretrieve(\"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/train_data.pgz\", \"train_data.pgz\")\n",
    "if not os.path.isfile('test_data.pgz'):\n",
    "    U.urlretrieve(\"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/test_data.pgz\", \"test_data.pgz\")\n",
    "if not os.path.isfile('vocab_list.pgz'):\n",
    "    U.urlretrieve( \"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/vocab_list.pgz\", \"vocab_list.pgz\" );\n",
    "end = time.time()\n",
    "print(\"Time elapsed (seconds):\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should take about 15 seconds\n",
      "Time elapsed (seconds): 9.447247505187988\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "    kwargs = {}\n",
    "except:\n",
    "    import _pickle as pickle\n",
    "    kwargs = {'encoding':'bytes'}\n",
    "    \n",
    "import gzip\n",
    "import numpy as np\n",
    "start = time.time()\n",
    "print(\"Should take about 15 seconds\")\n",
    "train_data, train_label = pickle.load( gzip.open( \"train_data.pgz\", \"rb\" ), **kwargs )\n",
    "train_label = np.asarray(train_label)\n",
    "test_data = pickle.load( gzip.open( \"test_data.pgz\", \"rb\" ),**kwargs )\n",
    "vocab_list = pickle.load( gzip.open( \"vocab_list.pgz\", \"rb\" ),**kwargs )\n",
    "end = time.time()\n",
    "print(\"Time elapsed (seconds):\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'absolutely', 'across', 'act', 'acted', 'acting', 'action', 'actor', 'actors', 'actress', 'actual', 'actually', 'add', 'admit', 'adult', 'adventure', 'age', 'ago', 'agree', 'air', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'amazing', 'america', 'american', 'among', 'amusing', 'animated', 'animation', 'annoying', 'another', 'anyone', 'anything', 'anyway', 'apart', 'apparently', 'appear', 'appears', 'appreciate', 'around', 'art', 'ask', 'atmosphere', 'attempt', 'attempts', 'attention', 'audience', 'average', 'avoid', 'away', 'awful', 'baby', 'back', 'background', 'bad', 'badly', 'band', 'based', 'basic', 'basically', 'battle', 'beautiful', 'beauty', 'became', 'become', 'becomes', 'begin', 'beginning', 'begins', 'behind', 'believable', 'believe', 'ben', 'best', 'better', 'beyond', 'big', 'biggest', 'bill', 'bit', 'bizarre', 'black', 'blood', 'body', 'book', 'books', 'bored', 'boring', 'box', 'boy', 'boys', 'break', 'brilliant', 'bring', 'brings', 'british', 'brother', 'brothers', 'brought', 'budget', 'bunch', 'business', 'buy', 'call', 'called', 'came', 'camera', 'cannot', 'car', 'care', 'career', 'cartoon', 'case', 'cast', 'casting', 'cat', 'caught', 'cause', 'century', 'certain', 'certainly', 'chance', 'change', 'character', 'characters', 'cheap', 'check', 'cheesy', 'child', 'children', 'choice', 'christmas', 'cinema', 'cinematography', 'city', 'class', 'classic', 'clear', 'clearly', 'clever', 'clich', 'close', 'co', 'cold', 'come', 'comedy', 'comes', 'comic', 'coming', 'comment', 'comments', 'common', 'company', 'compared', 'complete', 'completely', 'concept', 'consider', 'considering', 'control', 'convincing', 'cool', 'cop', 'copy', 'could', 'country', 'couple', 'course', 'cover', 'crap', 'crazy', 'create', 'created', 'credit', 'credits', 'creepy', 'crew', 'crime', 'cut', 'cute', 'dance', 'dancing', 'dark', 'daughter', 'david', 'day', 'days', 'de', 'dead', 'deal', 'death', 'decent', 'decided', 'decides', 'deep', 'definitely', 'depth', 'deserves', 'despite', 'development', 'dialog', 'dialogue', 'die', 'died', 'different', 'difficult', 'directed', 'directing', 'direction', 'director', 'directors', 'disappointed', 'disney', 'doctor', 'documentary', 'dog', 'done', 'doubt', 'dr', 'drama', 'dramatic', 'dream', 'due', 'dull', 'dumb', 'dvd', 'earlier', 'early', 'earth', 'easily', 'easy', 'editing', 'effect', 'effective', 'effects', 'effort', 'either', 'elements', 'else', 'emotional', 'end', 'ended', 'ending', 'ends', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough', 'entertaining', 'entertainment', 'entire', 'entirely', 'episode', 'episodes', 'era', 'escape', 'especially', 'etc', 'even', 'events', 'eventually', 'ever', 'every', 'everyone', 'everything', 'evil', 'exactly', 'example', 'excellent', 'except', 'exciting', 'expect', 'expected', 'expecting', 'experience', 'extremely', 'eye', 'eyes', 'face', 'fact', 'fails', 'fairly', 'fall', 'falls', 'familiar', 'family', 'famous', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fast', 'father', 'favorite', 'fear', 'feature', 'features', 'feel', 'feeling', 'feels', 'felt', 'female', 'fi', 'fight', 'fighting', 'figure', 'filled', 'film', 'filmed', 'filmmakers', 'films', 'final', 'finally', 'find', 'finds', 'fine', 'fire', 'first', 'five', 'flat', 'flick', 'focus', 'follow', 'following', 'follows', 'footage', 'force', 'forced', 'forget', 'form', 'former', 'forward', 'found', 'four', 'free', 'french', 'friend', 'friends', 'front', 'full', 'fun', 'funny', 'future', 'game', 'gave', 'gay', 'general', 'genre', 'george', 'german', 'get', 'gets', 'getting', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'go', 'god', 'goes', 'going', 'gone', 'good', 'gore', 'got', 'great', 'greatest', 'group', 'guess', 'gun', 'guy', 'guys', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happens', 'happy', 'hard', 'hardly', 'hate', 'head', 'hear', 'heard', 'heart', 'hell', 'help', 'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold', 'hollywood', 'home', 'hope', 'horrible', 'horror', 'hot', 'hour', 'hours', 'house', 'however', 'huge', 'human', 'humor', 'husband', 'idea', 'ideas', 'imagine', 'imdb', 'important', 'impressive', 'including', 'incredible', 'incredibly', 'indeed', 'inside', 'instead', 'intelligent', 'interest', 'interested', 'interesting', 'involved', 'island', 'italian', 'jack', 'james', 'jane', 'japanese', 'job', 'joe', 'john', 'joke', 'jokes', 'keep', 'keeps', 'kept', 'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kills', 'kind', 'king', 'knew', 'know', 'known', 'knows', 'la', 'lack', 'lady', 'lame', 'language', 'large', 'last', 'late', 'later', 'laugh', 'laughing', 'laughs', 'law', 'lead', 'leading', 'leads', 'learn', 'least', 'leave', 'leaves', 'lee', 'left', 'less', 'let', 'level', 'life', 'light', 'like', 'liked', 'line', 'lines', 'list', 'little', 'live', 'lives', 'living', 'local', 'long', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love', 'loved', 'low', 'mad', 'made', 'main', 'major', 'make', 'makes', 'making', 'male', 'man', 'manages', 'many', 'mark', 'married', 'mary', 'masterpiece', 'match', 'material', 'matter', 'may', 'maybe', 'mean', 'means', 'meant', 'meet', 'meets', 'members', 'memorable', 'men', 'mention', 'mentioned', 'mess', 'message', 'michael', 'middle', 'might', 'mind', 'minute', 'minutes', 'miss', 'missed', 'missing', 'modern', 'moment', 'moments', 'money', 'monster', 'mostly', 'mother', 'move', 'moves', 'movie', 'movies', 'moving', 'mr', 'much', 'murder', 'music', 'musical', 'must', 'mystery', 'name', 'named', 'nature', 'near', 'nearly', 'need', 'needed', 'needs', 'neither', 'never', 'new', 'next', 'nice', 'night', 'non', 'none', 'note', 'nothing', 'novel', 'nudity', 'number', 'obvious', 'obviously', 'odd', 'office', 'often', 'oh', 'ok', 'okay', 'old', 'older', 'one', 'ones', 'open', 'opening', 'opinion', 'order', 'original', 'oscar', 'others', 'otherwise', 'outside', 'overall', 'pace', 'parents', 'part', 'particular', 'particularly', 'parts', 'party', 'past', 'paul', 'pay', 'people', 'perfect', 'perfectly', 'performance', 'performances', 'perhaps', 'period', 'person', 'personal', 'peter', 'picture', 'piece', 'place', 'plain', 'planet', 'play', 'played', 'playing', 'plays', 'please', 'plenty', 'plot', 'plus', 'point', 'pointless', 'points', 'police', 'political', 'poor', 'poorly', 'popular', 'portrayal', 'portrayed', 'positive', 'possible', 'possibly', 'potential', 'power', 'powerful', 'predictable', 'premise', 'present', 'pretty', 'previous', 'probably', 'problem', 'problems', 'produced', 'production', 'public', 'pure', 'put', 'quality', 'question', 'quickly', 'quite', 'rate', 'rated', 'rather', 'rating', 'read', 'reading', 'real', 'realistic', 'reality', 'realize', 'really', 'reason', 'reasons', 'recent', 'recently', 'recommend', 'red', 'relationship', 'release', 'released', 'remake', 'remember', 'rent', 'respect', 'rest', 'result', 'return', 'revenge', 'review', 'reviews', 'rich', 'richard', 'ridiculous', 'right', 'robert', 'rock', 'role', 'roles', 'romance', 'romantic', 'room', 'run', 'running', 'runs', 'sad', 'sadly', 'said', 'save', 'saw', 'say', 'saying', 'says', 'scary', 'scene', 'scenes', 'school', 'sci', 'science', 'score', 'scott', 'screen', 'screenplay', 'script', 'season', 'second', 'secret', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'sees', 'self', 'sense', 'sequel', 'sequence', 'sequences', 'series', 'serious', 'seriously', 'set', 'sets', 'setting', 'several', 'sex', 'sexual', 'shame', 'short', 'shot', 'shots', 'show', 'showing', 'shown', 'shows', 'side', 'silly', 'similar', 'simple', 'simply', 'since', 'singing', 'single', 'sister', 'sit', 'situation', 'slightly', 'slow', 'small', 'social', 'society', 'solid', 'somehow', 'someone', 'something', 'sometimes', 'somewhat', 'son', 'song', 'songs', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'soundtrack', 'space', 'speak', 'special', 'spend', 'spent', 'spirit', 'spoilers', 'stage', 'stand', 'star', 'stars', 'start', 'started', 'starts', 'state', 'stay', 'still', 'stop', 'store', 'stories', 'story', 'storyline', 'straight', 'strange', 'street', 'strong', 'studio', 'stuff', 'stupid', 'style', 'subject', 'success', 'successful', 'suddenly', 'super', 'superb', 'supporting', 'supposed', 'sure', 'surprise', 'surprised', 'suspense', 'sweet', 'take', 'taken', 'takes', 'taking', 'tale', 'talent', 'talented', 'talk', 'talking', 'team', 'television', 'tell', 'telling', 'tells', 'ten', 'tension', 'terrible', 'th', 'theater', 'theme', 'thing', 'things', 'think', 'thinking', 'third', 'though', 'thought', 'three', 'thriller', 'throughout', 'time', 'times', 'title', 'today', 'together', 'told', 'tom', 'tone', 'tony', 'took', 'top', 'total', 'totally', 'towards', 'town', 'trash', 'tried', 'tries', 'trouble', 'true', 'truly', 'truth', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'twist', 'two', 'type', 'typical', 'ultimately', 'understand', 'unfortunately', 'unique', 'unless', 'unlike', 'upon', 'us', 'use', 'used', 'uses', 'using', 'usual', 'usually', 'value', 'various', 'version', 'video', 'view', 'viewer', 'viewers', 'viewing', 'villain', 'violence', 'violent', 'visual', 'voice', 'wait', 'waiting', 'walk', 'want', 'wanted', 'wants', 'war', 'waste', 'wasted', 'watch', 'watched', 'watching', 'water', 'way', 'ways', 'weak', 'weird', 'well', 'went', 'western', 'whatever', 'whether', 'white', 'whole', 'whose', 'wife', 'william', 'wish', 'within', 'without', 'woman', 'women', 'wonder', 'wonderful', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worse', 'worst', 'worth', 'would', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'year', 'years', 'yes', 'yet', 'york', 'young', 'younger', 'zombie', 'zombies']\n"
     ]
    }
   ],
   "source": [
    "#Consider using small set of the data\n",
    "trainData = train_data[:10000, :]\n",
    "validData = train_data[10000:15000, :]\n",
    "trainLabel = train_label[:10000]\n",
    "validLabel = train_label[10000:15000]\n",
    "testData = test_data[:10000, :]\n",
    "print( vocab_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.01049613e-15, -5.65727465e-16,  2.07511563e-15, -1.25034871e-15,\n",
       "        8.93827234e-16,  2.09658957e-16,  1.24238841e-15,  1.42255097e-16,\n",
       "        1.64055436e-15, -9.47040224e-16,  2.49471777e-15, -2.77537993e-16,\n",
       "       -1.35806033e-15, -2.28569386e-16, -4.80685491e-16,  4.10660395e-17,\n",
       "       -1.47469592e-15, -2.29052333e-16,  1.79992687e-15,  5.72459857e-16,\n",
       "       -7.98441313e-16, -7.43938244e-17, -1.37430067e-15, -4.51683135e-16,\n",
       "        5.87072613e-16, -1.25504496e-15,  7.40705275e-16, -1.24832367e-15,\n",
       "       -2.98550518e-15, -2.53230104e-15, -2.07554862e-15, -1.01518793e-17,\n",
       "        5.15988363e-16, -3.17301740e-16, -1.22530652e-15,  1.63173031e-15,\n",
       "       -1.02405640e-15, -4.67292871e-16, -3.91819910e-17, -1.19720900e-15,\n",
       "        2.47845300e-15, -1.31523681e-16,  6.25703933e-16,  2.51556553e-16,\n",
       "        1.78223658e-15, -1.40591760e-15,  7.31237293e-16, -8.80038264e-16,\n",
       "       -8.96323016e-16,  7.37727657e-16,  8.86091200e-16, -1.26235244e-15,\n",
       "       -4.65816274e-16,  7.35764782e-16, -9.39963662e-16,  3.27660121e-16,\n",
       "       -7.29555305e-16, -7.02549130e-17,  7.68816122e-16,  1.80150561e-15,\n",
       "       -1.61279656e-15,  8.43154435e-16,  1.01290087e-16, -8.83166873e-16,\n",
       "        1.22529320e-15, -1.20171983e-15, -1.47377222e-15, -1.69755321e-16,\n",
       "       -1.13765664e-15, -3.42539108e-15,  1.81495929e-15,  1.02292397e-15,\n",
       "       -5.55755442e-17, -1.03895559e-15, -7.87481191e-17,  7.18989313e-16,\n",
       "        9.81437154e-19,  9.75383108e-16, -7.74407205e-16, -8.23574542e-16,\n",
       "       -1.01402442e-15,  3.20503624e-16, -4.79116746e-16, -1.03097531e-16,\n",
       "        1.40933487e-15, -3.94573263e-16,  4.78002082e-16, -7.11430914e-18,\n",
       "       -2.43287612e-16,  2.28898456e-15, -1.43313361e-15,  1.46509249e-15,\n",
       "       -1.98862482e-15, -1.30762068e-17, -6.47351062e-16,  1.45788936e-16,\n",
       "        1.21128219e-15,  2.37354580e-16,  1.76745174e-15, -1.93071559e-15,\n",
       "        9.48741086e-16,  4.07502920e-16, -9.38817912e-16, -8.92610430e-16,\n",
       "        3.25179883e-16,  2.36988873e-15,  2.25215402e-16,  7.93161092e-16,\n",
       "       -2.62359023e-16, -1.17639232e-15,  5.67770275e-16, -6.75564049e-16,\n",
       "       -1.60262248e-15, -1.10456089e-15, -1.80880422e-15, -1.84725568e-16,\n",
       "        5.26514388e-16, -7.59681207e-17, -1.07724940e-15,  3.15438786e-16,\n",
       "        6.91339208e-16, -8.49844639e-16, -1.53317359e-16, -7.82891529e-16,\n",
       "        2.16185958e-15,  8.82476314e-16,  9.50794998e-17, -6.24167384e-16,\n",
       "        6.38027409e-16, -2.83209012e-16,  5.67299541e-16,  2.11542561e-15,\n",
       "       -1.32543532e-15,  1.21730181e-15, -1.62287073e-15,  2.84945401e-16,\n",
       "       -3.60791397e-16,  3.29047900e-17,  1.50068624e-15,  7.86022358e-16,\n",
       "        1.80736537e-15,  9.44642142e-16, -1.51694879e-15,  5.72326631e-16,\n",
       "        8.80964190e-16, -4.40654180e-16,  7.95490340e-16, -1.13306697e-15,\n",
       "        7.62645502e-16, -3.13096216e-16,  6.70317135e-16, -4.00874889e-16,\n",
       "        2.14348317e-15, -6.71880329e-16, -1.02675646e-16,  7.32527372e-16,\n",
       "       -1.14027232e-15,  4.82573981e-16,  1.19176446e-15, -6.91844360e-16,\n",
       "        3.82704979e-16, -4.89652763e-17, -1.51304747e-15,  2.28078889e-15,\n",
       "       -7.22819582e-16,  2.17898366e-15, -3.08735260e-16, -2.12693863e-15,\n",
       "        1.62317271e-15, -8.82129925e-16, -4.35361081e-15,  8.50559623e-16,\n",
       "       -2.59939625e-15,  7.69695419e-17,  7.42497175e-16, -3.76860765e-16,\n",
       "        5.08189046e-16,  3.69073661e-16, -3.37663231e-17, -3.99542621e-16,\n",
       "       -9.36388744e-16,  1.39301903e-16,  3.04852144e-15, -1.93018268e-15,\n",
       "       -4.64883687e-16, -6.18853857e-16, -1.20092269e-15,  9.00102215e-17,\n",
       "        2.85445001e-16,  6.46807052e-16, -2.77200485e-16,  3.23784111e-15,\n",
       "        1.80306992e-15, -9.08850772e-17, -2.87099011e-15, -1.35207401e-15,\n",
       "       -2.16898277e-15,  3.86011223e-16,  4.66371386e-16, -9.33495503e-16,\n",
       "        2.83064683e-16,  5.12265785e-16,  1.83225879e-15, -7.93938248e-16,\n",
       "        8.40549852e-17, -1.72857062e-15, -3.32640582e-16,  1.23729693e-15,\n",
       "        1.02066799e-15, -1.61660907e-15,  2.23810970e-15, -6.08701978e-16,\n",
       "        8.40421066e-16,  5.26723110e-16,  1.37731160e-15,  5.46973578e-16,\n",
       "       -6.82238710e-16, -1.51072599e-15, -2.85594881e-16,  1.84298299e-15,\n",
       "        5.03018738e-16, -1.25950361e-15, -2.99009706e-16,  1.03612785e-15,\n",
       "        6.08171291e-16, -1.97274419e-15, -1.04659392e-15, -6.35391739e-16,\n",
       "       -1.13860921e-15, -8.10260747e-16,  2.64699374e-16, -5.95927752e-16,\n",
       "        3.98461264e-16, -1.64336322e-15, -1.76401782e-15,  1.05438103e-15,\n",
       "        3.07598391e-17, -5.64719382e-16, -1.31222144e-15,  1.31936906e-15,\n",
       "       -1.87171167e-15, -4.21866986e-16, -1.16513688e-15,  3.51972229e-15,\n",
       "        1.25079502e-15,  6.43143316e-16, -2.81463741e-16,  7.26956273e-16,\n",
       "        9.42057543e-16,  9.05937547e-16,  2.52986521e-16,  1.69237069e-15,\n",
       "        9.67879110e-16,  1.90845117e-15,  1.70089054e-15,  5.67528247e-16,\n",
       "        1.29566802e-15, -8.01847477e-17, -9.83446657e-16,  9.03590536e-16,\n",
       "        1.78297155e-15,  2.50878207e-16, -1.36745726e-15,  7.34110550e-16,\n",
       "       -3.44035911e-17, -5.54194468e-16,  3.23374660e-16,  2.30283792e-15,\n",
       "       -9.75100001e-16, -5.55875346e-16, -8.49529336e-16, -2.10313988e-16,\n",
       "       -2.47004639e-16, -1.34216194e-15,  8.74256223e-16,  2.36015651e-16,\n",
       "       -8.22979462e-16, -4.06519263e-16, -1.96220817e-15,  1.08080211e-16,\n",
       "        1.51324286e-15,  9.38553679e-16, -3.60014241e-16, -5.10065323e-16,\n",
       "       -2.37961872e-15, -1.14221965e-15,  1.04619202e-15, -1.28068001e-15,\n",
       "        2.27775576e-16, -1.63726810e-15, -1.45277346e-15, -2.53934651e-16,\n",
       "        1.91931804e-15, -2.64466227e-16, -2.42852405e-16, -1.76143544e-16,\n",
       "       -1.45716217e-15,  5.09858822e-17,  1.01081810e-15, -1.37288625e-15,\n",
       "       -4.04625222e-16, -4.26707558e-16, -4.44015935e-16, -6.88258339e-16,\n",
       "        3.20263815e-16,  2.27871055e-16, -3.40202755e-15,  3.42141870e-16,\n",
       "       -2.42306175e-16, -8.56514859e-17,  1.62279967e-15, -1.16465282e-15,\n",
       "        5.42597078e-16, -9.43749523e-16,  7.75202125e-17,  8.09790013e-16,\n",
       "       -1.43447920e-15, -1.98935313e-15,  5.66415803e-16, -6.53102017e-16,\n",
       "       -9.67537162e-17, -1.06182618e-15,  7.31630312e-16, -8.17186319e-16,\n",
       "        1.17837740e-15,  1.38239642e-15,  8.42337311e-16, -7.39326378e-16,\n",
       "       -6.85529411e-16, -1.46602730e-15,  5.74535974e-16, -1.84225968e-15,\n",
       "        1.22780786e-15, -4.60879113e-16,  1.19361632e-15,  2.86535240e-16,\n",
       "        9.62385727e-16,  1.64419589e-16,  1.21228805e-15,  1.11285647e-15,\n",
       "       -4.72681894e-16, -1.38143719e-15, -4.10032674e-15,  5.58657565e-16,\n",
       "        6.58195720e-16, -2.35502506e-15, -2.87945223e-16,  5.56732438e-16,\n",
       "        8.97104613e-16,  6.38427977e-15,  1.23118404e-15,  7.23738847e-16,\n",
       "       -2.47034615e-16, -4.90274488e-18, -1.04046771e-15,  9.98705563e-16,\n",
       "       -5.17786924e-16,  2.01687556e-16, -1.73276060e-15,  7.48778817e-16,\n",
       "        3.81792375e-16, -1.60817804e-15,  1.39002365e-15, -1.22469146e-15,\n",
       "        7.67157449e-16,  4.75444129e-16,  1.74609882e-15,  9.62523394e-16,\n",
       "       -2.01025641e-15,  5.29656319e-16, -2.51125343e-15, -1.89397387e-16,\n",
       "       -4.14903667e-16, -7.54230012e-16, -1.80813586e-15,  1.05190967e-15,\n",
       "        1.51519908e-15,  1.44666279e-15, -3.67261777e-16,  1.62605152e-15,\n",
       "       -6.69926337e-16,  5.15720799e-17,  5.64346347e-16, -1.64827929e-15,\n",
       "       -7.23796578e-16, -2.00879313e-16, -1.55557789e-16,  8.37641068e-17,\n",
       "        5.77036197e-16,  7.74333930e-16,  3.24629212e-15,  4.64439598e-16,\n",
       "        4.30380176e-16,  1.88178140e-15, -4.55038229e-16,  3.09205772e-15,\n",
       "       -1.42419410e-15,  6.39313047e-16, -1.20121135e-15,  1.95796712e-16,\n",
       "        1.26051614e-15,  1.36852751e-16, -3.82869292e-16,  2.21473950e-16,\n",
       "       -1.27358790e-15, -4.16287005e-16, -5.68209924e-15, -1.76946235e-15,\n",
       "        1.90158334e-15,  3.31832339e-16,  1.96584971e-16,  1.32619471e-15,\n",
       "       -1.03672626e-17, -7.81243958e-16, -1.02607478e-15,  5.90767435e-16,\n",
       "        8.58220162e-16, -8.40387759e-16, -2.28958408e-15,  1.14912968e-15,\n",
       "        6.69300171e-16,  3.89450694e-16,  1.91666238e-15,  8.94695429e-16,\n",
       "       -2.16034524e-15, -1.06986642e-15, -8.89555096e-16, -7.05824510e-15,\n",
       "        2.22373231e-16,  6.09214901e-16, -1.59909641e-15, -1.00092379e-15,\n",
       "       -1.21928023e-15,  9.96003280e-17,  7.98143773e-16, -3.20383720e-16,\n",
       "       -1.40320422e-15,  1.14073195e-16, -1.19245835e-15,  2.61661248e-15,\n",
       "       -8.59683436e-16, -3.36477513e-16, -2.88017499e-15,  2.33910669e-16,\n",
       "        1.45113699e-15, -2.22970531e-16,  2.81241697e-16, -2.71362044e-15,\n",
       "       -7.16167126e-16,  6.00761663e-16, -3.46194184e-16,  1.05916387e-15,\n",
       "        7.60058683e-18, -5.80957504e-16,  2.11162199e-16, -3.92901267e-16,\n",
       "       -1.05036202e-15, -9.42925737e-16,  4.96735986e-16,  1.31188393e-15,\n",
       "        4.62951899e-16, -4.57354155e-16, -8.15172374e-16,  1.19555033e-15,\n",
       "       -1.18713928e-15,  8.72425465e-16,  8.46549497e-16,  1.63259628e-15,\n",
       "       -1.65449876e-16, -2.32482922e-16,  1.44964041e-16,  1.12997389e-15,\n",
       "        1.16461063e-15,  1.87034832e-16,  7.58570984e-17, -1.59148028e-15,\n",
       "        7.08729742e-16,  7.64206476e-16, -1.33933753e-15, -1.16226140e-15,\n",
       "       -6.96385172e-16, -8.31721358e-16, -3.15669713e-16,  1.03204778e-15,\n",
       "       -4.48713067e-15, -4.47104576e-16,  3.51190188e-16,  3.81921161e-16,\n",
       "       -1.28529853e-15, -3.39968054e-16, -1.01660902e-15,  1.40057743e-15,\n",
       "        1.08048459e-15, -7.29267757e-16, -1.11944232e-15, -1.43718148e-15,\n",
       "       -1.12851506e-15, -4.92599295e-16,  1.50271129e-15,  9.46276391e-16,\n",
       "        1.09838361e-15, -3.72675224e-16,  1.04796172e-15, -1.79962933e-15,\n",
       "       -2.01878958e-15, -4.08428846e-16, -1.09208420e-15, -3.72324394e-17,\n",
       "        2.88049362e-15,  4.66591210e-16,  1.21038957e-15,  4.00370848e-16,\n",
       "        1.03633768e-15, -2.47162291e-16, -1.36179068e-15, -3.39087647e-15,\n",
       "       -1.63911551e-15,  1.75500503e-15, -1.33599798e-16, -1.18780541e-15,\n",
       "       -1.44243284e-15,  5.50011148e-16, -1.31851863e-15,  7.09172721e-16,\n",
       "       -1.79124271e-15, -2.01153538e-16,  1.93948191e-15,  1.78321136e-15,\n",
       "       -1.09379616e-15, -5.62214719e-16,  3.62199160e-17,  1.16454402e-15,\n",
       "        1.16975096e-15,  1.59313229e-15,  4.73725503e-16,  4.82356377e-16,\n",
       "       -1.00860875e-15, -7.86215537e-17, -7.57691687e-16,  2.27989627e-15,\n",
       "       -1.10584208e-15, -7.76596565e-16, -2.05278017e-16, -1.06781251e-17,\n",
       "        3.33555406e-16,  1.27129640e-15,  1.03743236e-15, -9.84470283e-16,\n",
       "        5.51031443e-16, -2.75259815e-16, -5.55548940e-16,  2.62147637e-15,\n",
       "       -7.65607577e-16, -1.97158623e-15, -4.40418813e-16, -1.62436731e-16,\n",
       "       -5.00013364e-16,  6.18908258e-16, -2.78237433e-16,  1.59463553e-16,\n",
       "       -8.10669309e-16,  1.59925406e-15,  5.38702416e-16, -5.32844879e-16,\n",
       "       -1.88827620e-15, -8.24982305e-16,  4.33963976e-17,  7.41338102e-16,\n",
       "       -1.50222057e-16, -7.35118633e-16,  1.90444549e-15,  8.11322121e-16,\n",
       "        2.63892241e-15, -1.85807814e-15,  1.31739064e-17,  1.01789688e-15,\n",
       "        1.46938017e-16, -1.82858173e-16, -4.24904556e-17, -3.92641475e-17,\n",
       "        1.36881395e-15, -2.50485854e-15,  2.39718911e-15, -2.73565615e-15,\n",
       "       -1.97735384e-15,  5.43547429e-16,  6.57525145e-16,  1.09538822e-15,\n",
       "       -4.48323600e-16, -1.66423320e-15,  1.08198006e-15, -1.68041359e-15,\n",
       "       -6.84352575e-16,  2.09742668e-15,  1.26732180e-15, -7.50137730e-16,\n",
       "       -2.24165908e-15, -1.26831878e-17,  3.83499899e-16, -1.08040021e-15,\n",
       "        1.06356257e-15,  1.33883127e-15,  1.00962794e-15,  7.48695550e-17,\n",
       "       -4.75559592e-16, -5.40136824e-16, -1.64961156e-15, -7.45425943e-16,\n",
       "        8.71835937e-17,  1.28401734e-15,  6.19442275e-16,  9.26689836e-16,\n",
       "       -1.34119160e-15,  3.41999762e-16,  6.82545132e-16,  9.48290335e-16,\n",
       "        2.41806575e-18,  1.18979049e-15, -1.00420117e-15, -1.25283561e-15,\n",
       "       -5.44246870e-16, -7.51200213e-16,  6.67814692e-16,  1.33583811e-15,\n",
       "       -7.16937620e-16,  1.02368780e-15, -1.58266955e-15, -1.04375619e-15,\n",
       "        9.05160391e-16,  4.12834211e-16, -9.05011621e-16, -1.73718817e-16,\n",
       "       -1.58068891e-15, -2.53648880e-15,  1.00627284e-15,  6.38162856e-16,\n",
       "        2.86599633e-16, -9.16777765e-17,  3.02535774e-17,  1.06917808e-16,\n",
       "        2.91735525e-16, -3.28341798e-16, -5.23738830e-16, -3.33812977e-16,\n",
       "       -1.21620491e-16, -2.52231569e-16, -7.31015248e-16,  1.37951872e-16,\n",
       "       -1.41607170e-15, -1.01416653e-15, -8.90023610e-16,  1.12805765e-15,\n",
       "       -3.14532844e-16, -1.22214683e-15, -1.01070485e-15, -1.15358390e-15,\n",
       "       -7.26041449e-16, -1.38249856e-15,  3.45347750e-15,  3.38922224e-16,\n",
       "        1.14007692e-15,  6.26778629e-16,  1.19417143e-15, -2.44956722e-15,\n",
       "        1.21798793e-15, -1.89707361e-15, -2.27687202e-15, -1.30718991e-15,\n",
       "        1.00311759e-15,  1.98766781e-15,  1.06439302e-15, -3.01040304e-16,\n",
       "        2.19589458e-15,  1.10560450e-15, -1.01798570e-15, -3.06977332e-15,\n",
       "       -8.22524271e-16, -2.59670063e-16,  1.25355282e-16,  7.04492020e-16,\n",
       "        1.13718812e-15,  2.80078183e-16,  1.64551039e-15, -2.18642882e-16,\n",
       "       -2.51466181e-15, -1.60172098e-15,  3.02755598e-15,  2.20903740e-15,\n",
       "       -1.09747988e-15, -1.59738889e-16,  8.49416093e-16, -4.29913882e-16,\n",
       "       -3.74734022e-15, -1.53650426e-16, -1.79010806e-15, -1.44925405e-15,\n",
       "       -5.49391643e-16, -1.12170162e-15, -5.60218538e-16,  3.29016814e-16,\n",
       "       -1.46159751e-15,  8.63301652e-16, -3.56308316e-16,  1.82002857e-15,\n",
       "        2.51065835e-15,  1.13661969e-15, -1.76380688e-15,  5.83815218e-16,\n",
       "       -5.17070831e-16, -5.21376275e-16, -1.93126404e-15,  9.69251346e-16,\n",
       "       -6.55966392e-16, -1.23568489e-15,  2.45599097e-15, -6.86774193e-15,\n",
       "        6.86500856e-16,  1.63287162e-16,  1.70159664e-15,  2.20597984e-15,\n",
       "        7.91411381e-16, -1.50042201e-16,  1.75524040e-16, -8.47142356e-16,\n",
       "        1.28497879e-15, -4.69668748e-16,  1.36204381e-16,  2.69030576e-15,\n",
       "       -7.01880776e-16,  3.12105897e-16,  9.38471523e-17, -1.47222234e-16,\n",
       "       -3.47037954e-15,  6.02902173e-16,  8.33608738e-16, -2.64663846e-16,\n",
       "        5.77219383e-16,  1.45618739e-15, -6.68601841e-16, -1.00374598e-15,\n",
       "        1.86462401e-15, -1.16314514e-15,  1.59730895e-15,  8.53344062e-16,\n",
       "        5.96656058e-16, -1.04442677e-15, -2.02925454e-16, -8.33786373e-16,\n",
       "        9.24011978e-16,  9.02002917e-16,  1.84334104e-15, -6.03073147e-17,\n",
       "       -1.03340447e-15, -2.83826296e-16, -7.58724195e-16,  2.95710123e-16,\n",
       "        1.08416609e-15, -1.03856035e-15, -1.77489801e-15, -1.05960574e-15,\n",
       "        1.73201453e-16, -6.54776233e-16, -9.27702359e-16, -5.81446002e-16,\n",
       "       -3.40424133e-15,  6.76334544e-16, -2.73867595e-16,  5.23097787e-15,\n",
       "       -2.44375631e-16, -2.24971375e-15,  3.12749826e-17,  4.53173055e-16,\n",
       "       -1.93089988e-16, -7.59179386e-16,  6.82813805e-16, -5.33706412e-16,\n",
       "       -4.21496171e-16,  4.49795756e-17,  1.16467946e-15, -5.82505155e-16,\n",
       "        1.09214859e-16,  2.23773444e-15, -2.71138667e-17, -7.70310482e-16,\n",
       "        4.18356461e-16, -9.36841715e-16,  1.44698586e-15,  1.06401998e-15,\n",
       "        1.04914522e-15, -2.58312260e-15,  7.55642215e-16, -3.10935722e-16,\n",
       "        9.71960290e-16,  2.33257857e-17, -3.64308583e-16,  2.78248535e-16,\n",
       "       -1.63141722e-15,  4.65323335e-16, -4.23623359e-16, -1.02115205e-15,\n",
       "       -6.86162238e-16, -4.75788298e-16,  9.35935773e-16,  9.26907440e-16,\n",
       "        7.00073333e-16,  3.79041243e-16,  7.58149099e-17, -1.67277303e-16,\n",
       "       -2.23763452e-15,  8.38360492e-16,  1.68302039e-15,  1.02019726e-15,\n",
       "        9.48963130e-17,  5.51179102e-16,  3.73008291e-16, -1.38488554e-15,\n",
       "        6.85924650e-16,  3.27184946e-16,  1.05352838e-15,  1.64939395e-15,\n",
       "        1.44929624e-15,  1.56511248e-15,  4.39790426e-16,  1.87741378e-15,\n",
       "       -1.51401114e-16,  2.72324163e-15, -1.42108547e-16,  2.35022668e-15,\n",
       "       -4.60822491e-16, -1.12226672e-15,  1.55883084e-15, -1.58177471e-15,\n",
       "       -2.27113661e-15, -8.98845443e-16, -7.07811587e-17, -2.01738626e-16,\n",
       "       -1.41635592e-16, -1.40502721e-15, -1.10293774e-15, -1.22237553e-15,\n",
       "       -1.43516310e-15, -6.65413280e-16,  4.86695129e-16,  1.13693499e-16,\n",
       "       -3.86939369e-16,  5.41815481e-16,  2.00647277e-15,  1.12564180e-15,\n",
       "        1.14408927e-15,  4.73781014e-16, -9.16053899e-16,  1.15497834e-15,\n",
       "        2.52118326e-16,  1.58177693e-15,  1.40292666e-15,  2.65411471e-15,\n",
       "        1.07579057e-15,  1.59550373e-15,  4.06761291e-16, -2.40285569e-16,\n",
       "        8.04534217e-17,  8.93869423e-16,  6.32200958e-16, -1.40735423e-15,\n",
       "        4.31885638e-16, -3.19140270e-16,  2.27768915e-16,  8.37019343e-16,\n",
       "       -5.26467758e-18,  1.48290269e-16,  2.39102071e-16,  1.58175029e-15,\n",
       "        1.61453517e-15,  2.45592435e-16, -9.89763826e-17,  2.20072849e-16,\n",
       "        2.73541190e-16, -3.11662252e-15,  1.16726406e-15,  2.93984836e-16,\n",
       "        3.19273497e-16,  1.36010758e-15, -2.82966983e-16, -1.18283827e-15,\n",
       "       -3.68651776e-16,  2.52614596e-15, -8.19756485e-16,  4.02665679e-16,\n",
       "       -6.64406308e-16, -1.80826687e-15, -9.33659816e-16, -1.17425181e-15,\n",
       "       -3.69859698e-16, -8.83602080e-16,  5.16653387e-17, -2.62442290e-16,\n",
       "       -2.40951703e-16,  2.25333086e-16, -3.49569262e-16,  5.58291191e-16,\n",
       "        1.95135019e-16, -1.39682488e-15, -1.25318422e-15, -2.10450768e-15,\n",
       "       -4.56377158e-16, -1.10947029e-15, -1.22301502e-15, -6.94431179e-16,\n",
       "        4.87022200e-15, -1.13918652e-15, -6.52899956e-17, -3.75317555e-16,\n",
       "        1.26277877e-15, -7.96785971e-16, -2.44031462e-16,  1.53110857e-16,\n",
       "       -2.63351119e-15,  3.94773103e-17, -4.45332660e-16, -7.33453298e-16,\n",
       "       -1.10809140e-16,  4.00213196e-17, -2.56380028e-15,  4.46653825e-16,\n",
       "        5.79485349e-16,  1.15952137e-15, -3.00082181e-17,  5.23761035e-16,\n",
       "       -9.05469033e-16,  5.40134604e-16, -1.23445476e-15, -2.01105799e-17,\n",
       "       -7.68722863e-16,  1.18407950e-15,  1.15985443e-15, -3.78974629e-16,\n",
       "       -1.32738043e-15,  3.47761819e-16, -3.97466504e-16, -1.50528034e-15,\n",
       "       -5.69277958e-16,  1.46389567e-15, -9.17048659e-16,  8.91813290e-16,\n",
       "        1.92474037e-15,  1.96540784e-15,  1.57257984e-15,  1.32247324e-15,\n",
       "        2.23163710e-16,  2.63908895e-16,  9.42645961e-16, -5.14754905e-17,\n",
       "        2.46147547e-15, -1.07784670e-15,  1.04528608e-15, -1.98841388e-15,\n",
       "        8.34052827e-16, -1.35315759e-15,  4.50237625e-16,  7.30793204e-16,\n",
       "       -4.65065764e-16, -7.37252481e-16,  4.61204408e-16, -2.71648704e-15,\n",
       "        1.02251541e-17,  6.07587314e-16,  1.12117204e-15,  1.64812608e-16,\n",
       "        1.48451917e-15,  1.54324997e-15, -5.17383913e-16,  1.51905155e-16,\n",
       "       -7.62190311e-16,  1.29079858e-15, -2.12947437e-16, -2.10176765e-15,\n",
       "        1.01697983e-15,  1.18683730e-15, -1.02718056e-15,  9.08508824e-16,\n",
       "        7.43349826e-16, -5.92113025e-16,  2.59320121e-15, -6.71107614e-16,\n",
       "        5.94624350e-16,  9.58246815e-16,  1.31591182e-15, -5.07902609e-16,\n",
       "       -2.17807772e-15, -6.39570619e-16, -1.09645626e-15, -6.44924114e-16,\n",
       "        3.87543331e-16,  4.54729587e-16, -6.00821615e-16, -7.77637954e-16,\n",
       "        1.28648203e-16, -5.05835374e-16, -3.03977954e-16, -1.07331033e-15])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"top_of_steps\"></div>\n",
    "# Steps\n",
    "1. <a href=\"#Implement-logistic-regression-likelihood.\">Implement logistic regression likelihood.</a>\n",
    "2. <a href=\"#Compute-derivative-of-logistic-regression.\">Compute derivative of logistic regression.</a>\n",
    "3. <a href=\"#Check-gradient.\">Check gradient.</a>\n",
    "4. <a href=\"#Tweak-gradient-ascent-code.\">Tweak gradient ascent code.</a>\n",
    "5. <a href=\"#Report-results-and-analysis.\">Report results and analysis.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement logistic regression likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is given as $D = {(\\mathbf{x}_i, y_i):, i = 1...n}$, where $y_i \\in \\{-1, +1\\}$, and $\\mathbf{x}_i \\in R^p$. In this case there are n samples and each sample has p features. <br \\>\n",
    "\n",
    "For logistic regression, \n",
    "* We have model parameters: $\\mathbf{w} \\in R^p$ for weight and a bias term $b$.\n",
    "* For a sample x and its label y, $p(y|\\mathbf{x}, \\mathbf{w}, b) = \\frac{1}{1+exp\\{-y(\\mathbf{w} \\cdot \\mathbf{x} + b)\\}}$ \n",
    "* We can define $x' = \\begin{bmatrix} 1\\\\ x \\end{bmatrix}$, then $ \\mathbf{w}' =  \\begin{bmatrix} b\\\\ \\mathbf{w} \\end{bmatrix}$. Therefore the bias term is included in the weight vector. For notation brevity, we still use notations $x, \\mathbf{w}$ as $x', \\mathbf{w}'$. This can be implemented by numpy.concatenate function.\n",
    "* Hence the first entry of the vector $w'$ is bias term and the rest are feature weights. In the code you can use w[0] to access the bias term and w[1:] to access the feature weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#We help you do the concatenate, so the first feature becomes the  bias term\n",
    "train_data_pad = np.concatenate( ( np.ones((trainData.shape[0], 1)), trainData ), axis = 1 )\n",
    "test_data_pad = np.concatenate( ( np.ones((testData.shape[0], 1)), testData ), axis = 1 )\n",
    "valid_data_pad = np.concatenate( ( np.ones((validData.shape[0], 1)), validData ), axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do: \n",
    "1. Given the data $D = {(\\mathbf{x}_i, y_i)} $, write down the likelihood function ($L(\\mathbf{w})$) of logistic regression. ** [1 pt] **\n",
    "2. Take $\\log$ of the likelihood function in (1), write down the log likelihood function. Hint: $\\log$ will not cancel $\\exp$. ** [1 pt] **\n",
    "3. Add  ridge penalty in the log likelihood function (Let the weight of ridge penalty be $\\alpha$). Hint: Do not include $w_0$ in the ridge term. ** [1 pt] **\n",
    "4. Write a function to compute regularized log likelihood ** [1 pt] **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $ L(\\mathbf{w}) =  \\prod_i \\frac{1}{1 + exp\\{{y_i(\\mathbf{x}_i \\cdot \\mathbf{w})\\}}}$\n",
    "2. $ LL(\\mathbf{w}) = -\\sum_i log\\{{1+exp\\{-y_i(\\mathbf{x}_i \\cdot \\mathbf{w})} \\} \\} $\n",
    "3. $ PLL(\\mathbf{w}) = -\\sum_i log\\{{1+exp\\{-y_i(\\mathbf{x}_i \\cdot \\mathbf{w})} \\} \\} -\\frac{\\alpha}{2}\\sum_{j=1}^{p} \\mathbf{w}_j^2. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loglikelihood(w, X, y, alpha): \n",
    "    #compute loglikelihood for current w, b, given the data X, y\n",
    "    #w is a vector, b is a scalar, X is a n*p matrix and y is a vector.\n",
    "    tmp = 1. + np.exp(-y * (np.dot(X, w)))\n",
    "    penalty = -(alpha/2.)*np.sum(w[1:]**2)\n",
    "    return np.sum(-np.log(tmp)) + penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1808712118395306"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "np.random.seed(1)\n",
    "X = np.random.randn(2,3)\n",
    "y = np.array([1,-1])\n",
    "w = np.ones(3)\n",
    "w[[1]] = -1;\n",
    "loglikelihood(w, X, y, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1808712118395306\n"
     ]
    }
   ],
   "source": [
    "#the values printed in this cell should be the same as the value printed in the previous cell.\n",
    "print( -np.log(1+np.exp(-1*(X[0,0]-X[0,1]+X[0,2]))) - np.log(1+np.exp(1*(X[1,0]-X[1,1]+X[1,2]))) -1/2.*np.sum(w[1:]**2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute derivative of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize the function, we want to take the derivative of the function, and update $\\mathbf{w}$ according to the direction of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. Write down the derivative of the **penalized log likelihood function** for each $ w_j $. Hint: Remember that bias term is $w_0$ and treat it separately from the rest of $w_j$, $j\\in\\{1,...,p\\}$ ** [1 pt] **\n",
    "2. Write down the gradient of log likelihood function. Hint: You can express this in terms of probabilities. ** [1 pt] **\n",
    "3. Update the loglikelihood function to return both the loglikelihood and the gradient. ** [1 pt] **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <br>\n",
    "$ \\frac{\\partial PLL(\\mathbf{w})}{ \\partial w_0} = \\sum_i \\frac{y_i exp \\{ -y_i (\\mathbf{x} \\cdot \\mathbf{w}) \\} }{1 + exp\\{ -y_i(\\mathbf{x}_i \\cdot \\mathbf{w}) \\}}\n",
    "$ <br>\n",
    "$ \\frac{\\partial PLL(\\mathbf{w})}{ \\partial w_j} = \\sum_i  \\frac{y_i\\mathbf{x}_{i, j} exp \\{ -y_i (\\mathbf{x}_i \\cdot \\mathbf{w}) \\}}{1 + exp\\{ -y_i(\\mathbf{x}_i \\cdot \\mathbf{w}) \\}}  - \\alpha  \\mathbf{w}_j, j>0\n",
    "$ <br><br>\n",
    "2. <br>\n",
    "$ \\nabla PLL(\\mathbf{w}) = \\sum_i y_i - p(y_i | \\mathbf{x}_i, \\mathbf{w})y_i \\begin{bmatrix} 1 \\\\ \\vdots \\\\ \\mathbf{x}_{i, p}  \\end{bmatrix} - \\alpha \\begin{bmatrix} 0 \\\\ \\vdots \\\\ \\mathbf{w}_{i, p} \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loglikelihood(w, X, y, alpha): \n",
    "    #compute loglikelihood for current w, b, given the data X, y\n",
    "    #w is a vector, b is a scalar, X is a n*p matrix and y is a vector.\n",
    "    tmp = 1 + np.exp(-y * (np.dot(X, w)))\n",
    "    prob = 1./tmp\n",
    "    X = X.T #X becomes a p*n matrix so the gradVal can be computed straight-forwardly.\n",
    "    gradVal = np.dot(X, y - prob * y)\n",
    "    penalty = alpha/2.*np.sum(w[1:]**2)\n",
    "    gradPenalty = -alpha * w\n",
    "    gradPenalty[0] = 0\n",
    "    return -np.sum(np.log(tmp)) - penalty, gradVal + gradPenalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important we know the derivative we computed is correctly. We can check it by comparing it with numerical answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load grad_check.py\n",
    "def grad_check(f,xy0,delta=1e-6,tolerance=1e-7):\n",
    "    f0,g0 = f(xy0)\n",
    "    p = len(xy0)\n",
    "    finite_diff = np.zeros(p)\n",
    "    gradient_correct = True\n",
    "    for i in range(p):\n",
    "        xy1 = np.copy(xy0)\n",
    "        xy2 = np.copy(xy0)\n",
    "        xy1[i] = xy1[i] - 0.5*delta\n",
    "        xy2[i] = xy2[i] + 0.5*delta\n",
    "        f1,_ = f(xy1)\n",
    "        f2,_ = f(xy2)\n",
    "        finite_diff = (f2 - f1)/(delta)\n",
    "        if (abs(finite_diff - g0[i])>tolerance):\n",
    "            print(\"Broken partial\",i,\" Finite Diff: \",finite_diff,\" Partial: \",g0[i])\n",
    "            gradient_correct = False\n",
    "    return gradient_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We initialize the w vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
    "w_init[0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "* Here is the code to test if your gradient computation is correct (If the result is true, you get **1 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = lambda xy0: loglikelihood(xy0, X=train_data_pad[:,:15], y=trainLabel, alpha=1)\n",
    "grad_check( g, w_init[:15], delta=1e-6, tolerance=1e-5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak gradient ascent code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide the gradient ascent function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %load gradient_ascent\n",
    "def gradient_ascent(f,x,init_step,iterations):  \n",
    "    f_val,grad = f(x)                           # compute function value and gradient \n",
    "    f_vals = [f_val]\n",
    "    for it in range(iterations):                # iterate for a fixed number of iterations\n",
    "        #print 'iteration %d' % it\n",
    "        done = False                            # initial condition for done\n",
    "        line_search_it = 0                      # how many times we tried to shrink the step\n",
    "        step = init_step                        # reset step size to the initial size\n",
    "        while not done and line_search_it<100:  # are we done yet?\n",
    "            new_x = x + step*grad               # take a step along the gradient\n",
    "            new_f_val,new_grad = f(new_x)       # evaluate function value and gradient\n",
    "            if new_f_val<f_val:                 # did we go too far?\n",
    "                step = step*0.95                # if so, shrink the step-size\n",
    "                line_search_it += 1             # how many times did we shrank the step\n",
    "            else:\n",
    "                done = True                     # better than the last x, so we move on\n",
    "        \n",
    "        if not done:                            # did not find right step size\n",
    "            print(\"Line Search failed.\")\n",
    "        else:\n",
    "            f_val = new_f_val                   # ah, we are ok, accept the new x\n",
    "            x = new_x\n",
    "            grad = new_grad\n",
    "            f_vals.append(f_val)\n",
    "        plt.plot(f_vals)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Function value')\n",
    "    return f_val, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
    "w_init[0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "* Try different init_step (1e-4, 1e-5, 1e-6) using the following code, report the final regularized log-likelihood values. **[1 pt]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeFn( init_step, iterations, alpha, w):\n",
    "    g = lambda xy0: loglikelihood(xy0, train_data_pad, trainLabel, alpha)\n",
    "    f_val, update_w = gradient_ascent( g, w, init_step, iterations )\n",
    "    return f_val, update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should take about 6 seconds.\n",
      "Time elapsed (seconds): 1.1305108070373535\n",
      "final log-likelihood = -2602.170368\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('This should take about 6 seconds.')\n",
    "start = time.time()\n",
    "f_val, update_w=optimizeFn( init_step = 1e-4, iterations=100, alpha=0, w = w_init) #set init_step to 1e-4, 1e-5, 1e-6\n",
    "end = time.time()\n",
    "print('Time elapsed (seconds):', end-start)\n",
    "print('final log-likelihood = %f\\n' % (f_val)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final regularized log-likelihood values for (1e-4, 1e-5, 1e-6) are: -2602.170368, -3033.038249, -4707.155301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report results and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results, we need to have a prediction function, that uses the model we trained to predict the comment is positive and negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. Implement the prediction function. It should take as inputs feature weights and feature matrix. It should return vector of labels. **[1 pt]**\n",
    "2. Try different alpha (1000, 2000, 3000), and report which alpha produces the model that has the best accuracy on the validation set **[1 pt]**\n",
    "2. **[optional]** Report one sample that is classified wrong with high probabilites (> 90%). **[1 pt]**\n",
    "3. **[optional]** Report the words (entries in vocab_list associated with that feature) that cause the sample reported in (2) classify wrong. Note that weight w[i] correponds to word vocab_list[i-1], because we included bias term in w.**[1 pt]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w, validData ):\n",
    "    prob = 1./(1+np.exp(-np.dot(validData, w)));\n",
    "    res = np.zeros(validData.shape[0])\n",
    "    res[prob>=0.5] = 1\n",
    "    res[prob<0.5] = -1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the validation set 84.74%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see the accuracy on the validation set\n",
    "#when init_step=1e-5, the model has the best accuracy in the validation set\n",
    "f_val, update_w=optimizeFn( init_step = 1e-5, iterations=100, alpha=3000, w=w_init) #try different alphas [1000, 2000, 3000]\n",
    "pred = prediction(update_w, valid_data_pad)\n",
    "print( 'accuracy on the validation set {:.2f}%'.format( 100.*np.mean(pred==validLabel)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha = 1000 &rarr; 84.52% accuracy <br>\n",
    "alpha = 2000 &rarr; 84.60% accuracy <br>\n",
    "alpha = 3000 &rarr; 84.74% accuracy <br>\n",
    "<br>\n",
    "The best alpha is 3000, and the accuracy of this alpha is: 84.74%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Report one sample (sample index in the validation data set) that is classified wrong with high probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = np.nonzero( validLabel != pred )[0] #use this command to get the samples that are predicted wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the function to compute probability\n",
    "def computeProb(w, validData ):\n",
    "    prob = 1./(1+np.exp((np.dot(validData, w))))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  95  443  591 1473]\n"
     ]
    }
   ],
   "source": [
    "#get the samples that are classified wrong and with probabilites > 0.9\n",
    "probs = computeProb(update_w, valid_data_pad)\n",
    "wrong_idx_high = np.nonzero((validLabel != pred) & (probs > .9))[0]\n",
    "print(wrong_idx_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample index is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Report the words that cause the sample reported in (2) classify wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this function to get the most important words for each sample index\n",
    "#This function returns a list of top 10 words that influence the prediction.\n",
    "def getMostImportantFeatures( sampleIdx, validData, update_w, vocab_list ):\n",
    "    confusedList = []\n",
    "    intensity = validData[sampleIdx,:]*update_w\n",
    "    tmp = np.argsort( np.abs(intensity[0,:]) )[::-1]\n",
    "    for j in np.arange(10):\n",
    "        confusedList.append(vocab_list[tmp[j]-1])\n",
    "    return confusedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please',\n",
       " 'atmosphere',\n",
       " 'dull',\n",
       " 'poor',\n",
       " 'excellent',\n",
       " 'bad',\n",
       " 'point',\n",
       " 'job',\n",
       " 'make',\n",
       " 'silly']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusedList = getMostImportantFeatures( wrong_idx_high, valid_data_pad, update_w, vocab_list) #use the sample index got from the previous result\n",
    "confusedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file ids\n",
    "if not os.path.isfile('train_id.pgz'):\n",
    "    U.urlretrieve( \"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/train_id.pgz\", \"train_id.pgz\" );\n",
    "train_id = pickle.load( gzip.open( \"train_id.pgz\", \"rb\" ) )\n",
    "valid_id = train_id[10000:15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Retrieve the whole review and check if it is hard to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = valid_id[100]\n",
    "fileUrl = \"https://wwwx.cs.unc.edu/Courses/comp755-f18/hw1/reviews/\" + fileName + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('731_9', <http.client.HTTPMessage at 0x1f8010143c8>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.urlretrieve(fileUrl, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"#top_of_steps\">top</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
